<!DOCTYPE HTML>
<html>

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-1TRKDN34JX"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-1TRKDN34JX');
    </script>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Source+Sans+3&display=swap" rel="stylesheet">

    <title>DEVA</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- CSS only -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-+0n0xVW2eSR5OomGNYDnhzAbDsOXxcvSN1TPprVMTNDbiYZCxYbOOl7+AMvyTG2x" crossorigin="anonymous">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

    <link href="style.css" type="text/css" rel="stylesheet" media="screen,projection" />
</head>

<body>
    <br><br><br><br>
    <div class="container">
        <div class="row text-center" style="font-size:38px">
            <div class="col">
                Tracking Anything with Decoupled Video Segmentation
            </div>
        </div>

        <br>
        <div class="row text-center" style="font-size:28px">
            <div class="col">
                ICCV 2023
            </div>
        </div>
        <br>

        <div class="h-100 row text-center heavy justify-content-md-center" style="font-size:22px;">
            <div class="col-sm-2">
                <a href="https://hkchengrex.github.io/">Ho Kei Cheng</a>
            </div>
            <div class="col-sm-2">
                <a href="https://sites.google.com/view/seoungwugoh/">Seoung Wug Oh</a>
            </div>
            <div class="col-sm-2">
                <a href="https://www.brianpricephd.com/">Brian Price</a>
            </div>
            <div class="col-sm-2">
                <a href="https://www.alexander-schwing.de/">Alexander Schwing</a>
            </div>
            <div class="col-sm-2">
                <a href="https://joonyoung-cv.github.io/">Joon-Young Lee</a>
            </div>
        </div>

        <br>

        <div class="h-100 row text-center justify-content-md-center" style="font-size:20px;">
            <div class="col-sm-2">
                <a href="">[arXiv (soon)]</a>
            </div>
            <div class="col-sm-2">
                <a href="https://drive.google.com/file/d/1lAgg-j8d6EH1XYUz9htDaZDh4pxuIslb">[Paper]</a>
            </div>
            <div class="col-sm-2">
                <a href="https://github.com/hkchengrex/Tracking-Anything-with-DEVA">[Code & Demo]</a>
            </div>
        </div>

        <br>

        <hr>

        <div class="row" style="font-size:32px">
            <div class="col">
                Abstract
            </div>
        </div>
        <br>
        <div class="row">
            <div class="col">
                <p style="text-align: justify;">
                    Training data for video segmentation are expensive to annotate.
                    This impedes extensions of end-to-end algorithms to new video segmentation tasks, especially in
                    large-vocabulary settings.
                    To `track anything' without training on video data for every individual task, we develop a decoupled
                    video segmentation approach (DEVA), composed of task-specific image-level segmentation and
                    class/task-agnostic bi-directional temporal propagation.
                    Due to this design, we only need an image-level model for the target task (which is cheaper to
                    train) and a universal temporal propagation model which is trained once and generalizes across
                    tasks.
                    To effectively combine these two modules, we use bi-directional propagation for (semi-)online fusion
                    of segmentation hypotheses from different frames to generate a coherent segmentation.
                    We show that this decoupled formulation compares favorably to end-to-end approaches in several
                    data-scarce tasks including large-vocabulary video panoptic segmentation, open-world video
                    segmentation, referring video segmentation, and unsupervised video object segmentation.
                </p>
            </div>
        </div>
        <br>
        <hr>
        <br>

        <br>
        <hr>
        <br>
        <!-- 
        <div class="row" style="font-size:32px">
            <div class="col">
                Out-of-domain case
            </div>
        </div>
        <br>
        <center>
            <video style="width: 100%" controls>
                <source
                    src="https://user-images.githubusercontent.com/7107196/177920383-161f1da1-33f9-48b3-b8b2-09e450432e2b.mp4"
                    type="video/mp4">
                Your browser does not support the video tag.
            </video>
            Source: 
        </center> -->

        <br><br>

        <div style="font-size: 14px;">
            Contact: Ho Kei (Rex) Cheng (hkchengrex@gmail.com)
            <br>
        </div>

        <br><br>

    </div>

</body>

</html>