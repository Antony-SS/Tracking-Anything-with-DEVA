<!DOCTYPE HTML>
<html>

<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-1TRKDN34JX"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-1TRKDN34JX');
    </script>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Source+Sans+3&display=swap" rel="stylesheet">

    <title>DEVA</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- CSS only -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.1/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-+0n0xVW2eSR5OomGNYDnhzAbDsOXxcvSN1TPprVMTNDbiYZCxYbOOl7+AMvyTG2x" crossorigin="anonymous">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

    <link href="style.css" type="text/css" rel="stylesheet" media="screen,projection" />
</head>

<body>
    <br><br><br><br>
    <div class="container">
        <div class="row text-center" style="font-size:38px">
            <div class="col">
                Tracking Anything with Decoupled Video Segmentation
            </div>
        </div>

        <br>
        <div class="row text-center" style="font-size:28px">
            <div class="col">
                ICCV 2023
            </div>
        </div>
        <br>

        <div class="h-100 row text-center heavy justify-content-md-center" style="font-size:22px;">
            <div class="col-sm-2">
                <a href="https://hkchengrex.github.io/">Ho Kei Cheng</a>
            </div>
            <div class="col-sm-2">
                <a href="https://sites.google.com/view/seoungwugoh/">Seoung Wug Oh</a>
            </div>
            <div class="col-sm-2">
                <a href="https://www.brianpricephd.com/">Brian Price</a>
            </div>
            <div class="col-sm-2">
                <a href="https://www.alexander-schwing.de/">Alexander Schwing</a>
            </div>
            <div class="col-sm-2">
                <a href="https://joonyoung-cv.github.io/">Joon-Young Lee</a>
            </div>
        </div>

        <br>

        <div class="h-100 row text-center justify-content-md-center" style="font-size:20px;">
            <div class="col-sm-2">
                <a href="">[arXiv (soon)]</a>
            </div>
            <div class="col-sm-2">
                <a href="https://drive.google.com/file/d/1lAgg-j8d6EH1XYUz9htDaZDh4pxuIslb">[Paper]</a>
            </div>
            <div class="col-sm-2">
                <a href="https://github.com/hkchengrex/Tracking-Anything-with-DEVA">[Code & Demo]</a>
            </div>
        </div>

        <br>

        <hr>

        <div class="row" style="font-size:32px">
            <div class="col">
                Abstract
            </div>
        </div>
        <br>
        <div class="row">
            <div class="col">
                <p style="text-align: justify;">
                    Training data for video segmentation are expensive to annotate.
                    This impedes extensions of end-to-end algorithms to new video segmentation tasks, especially in
                    large-vocabulary settings.
                    To `track anything' without training on video data for every individual task, we develop a decoupled
                    video segmentation approach (DEVA), composed of task-specific image-level segmentation and
                    class/task-agnostic bi-directional temporal propagation.
                    Due to this design, we only need an image-level model for the target task (which is cheaper to
                    train) and a universal temporal propagation model which is trained once and generalizes across
                    tasks.
                    To effectively combine these two modules, we use bi-directional propagation for (semi-)online fusion
                    of segmentation hypotheses from different frames to generate a coherent segmentation.
                    We show that this decoupled formulation compares favorably to end-to-end approaches in several
                    data-scarce tasks including large-vocabulary video panoptic segmentation, open-world video
                    segmentation, referring video segmentation, and unsupervised video object segmentation.
                </p>
            </div>
        </div>
        <br>
        <hr>
        <br>
        
        <div class="row" style="font-size:32px">
            <div class="col">
                Piglets (text prompt: "pigs"):
            </div>
        </div>
        <br>
        <center>
            <video style="width: 100%" controls>
                <source
                    src="https://private-user-images.githubusercontent.com/7107196/265231689-57c5235d-f385-49d6-a342-98f7952cbc9b.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE2OTM2OTA2MjMsIm5iZiI6MTY5MzY5MDMyMywicGF0aCI6Ii83MTA3MTk2LzI2NTIzMTY4OS01N2M1MjM1ZC1mMzg1LTQ5ZDYtYTM0Mi05OGY3OTUyY2JjOWIubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQUlXTkpZQVg0Q1NWRUg1M0ElMkYyMDIzMDkwMiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMzA5MDJUMjEzMjAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZjdhZTE4OTI5ZGI5NGRiZTFjZmNkZGNjMTdkYmViMmRmNGE1NDQ2MTVlMGZiZWY0ODVjM2UxZDUyZmZlMDVmNiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.EHJd6c3GtVxzqX4gUHkqT36oNPzoPCfLhxV_wTMSyvs"
                    type="video/mp4">
                Your browser does not support the video tag.
            </video>
            Source: <a href="https://youtu.be/FbK3SL97zf8">https://youtu.be/FbK3SL97zf8</a>
        </center>

        <br>
        <hr>
        <br>

        <div class="row" style="font-size:32px">
            <div class="col">
                Demo with Segment Anything (automatic points-in-grid prompting); original video following annotations:
            </div>
        </div>
        <br>
        <center>
            <video style="width: 100%" controls>
                <source
                    src="https://private-user-images.githubusercontent.com/7107196/265231757-25ecfb37-47e2-4157-bb3d-b52193a53529.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE2OTM2OTA2MjMsIm5iZiI6MTY5MzY5MDMyMywicGF0aCI6Ii83MTA3MTk2LzI2NTIzMTc1Ny0yNWVjZmIzNy00N2UyLTQxNTctYmIzZC1iNTIxOTNhNTM1MjkubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQUlXTkpZQVg0Q1NWRUg1M0ElMkYyMDIzMDkwMiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMzA5MDJUMjEzMjAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9OTZlNTRlYjczZmZhNjg3MjJlNTg2MTdmOWQ2ODVlYzcyYWYwZjYzOTUxODg3NzU0Y2E2ZWZmMzUwYmMxMDFhYiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.W6V5bSPzqpH583kC9tHsMCVDiB-PB4ZNakG3c2-MGh4"
                    type="video/mp4">
                Your browser does not support the video tag.
            </video>
            Source: DAVIS 2017 validation set "soapbox"
        </center>

        <br>
        <hr>
        <br>

        <div class="row" style="font-size:32px">
            <div class="col">
                Demo with Segment Anything on a out-of-domain example; original video following annotations:
            </div>
        </div>
        <br>
        <center>
            <video style="width: 100%" controls>
                <source
                    src="https://private-user-images.githubusercontent.com/7107196/265231871-af0c7d58-4212-4ef2-b692-61263312e409.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTEiLCJleHAiOjE2OTM2OTA2MjMsIm5iZiI6MTY5MzY5MDMyMywicGF0aCI6Ii83MTA3MTk2LzI2NTIzMTg3MS1hZjBjN2Q1OC00MjEyLTRlZjItYjY5Mi02MTI2MzMxMmU0MDkubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQUlXTkpZQVg0Q1NWRUg1M0ElMkYyMDIzMDkwMiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyMzA5MDJUMjEzMjAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZmRiNGJkYmNkMjlmZjIwMDA2M2I5MzZmZjBkMjc0YTU1YmIyYWE5NjhiOTIyMzYyYzkwNzFlZjlmNTM4ZDkyZCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.ICK7cDx90tDDV0iOA9nMyR3DCzFKLt20tNdVxOn9mDw"
                    type="video/mp4">
                Your browser does not support the video tag.
            </video>
            Source: <a href="https://youtu.be/FQQaSyH9hZI">https://youtu.be/FQQaSyH9hZI</a>
        </center>

        <br><br>

        <div style="font-size: 14px;">
            Contact: Ho Kei (Rex) Cheng (hkchengrex@gmail.com)
            <br>
        </div>

        <br><br>

    </div>

</body>

</html>
